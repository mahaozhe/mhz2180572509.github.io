<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Poisson Distribution - Expectation, Variance, Likelihood and Regression</title>
    <url>/2022/4-ProbabilisticML-1-Poisson/</url>
    <content><![CDATA[<p>Poisson distribution can be used to express count data, which gives
number of events occurring in a fixed interval of time or space and
these events occur with a known constant mean rate and independently of
the time since the last event.</p>
<p>This blog aims to show the detailed proof of its expectation,
variance, likelihood and regression.</p>
<span id="more"></span>
<h1 id="probability-density-formula">Probability Density Formula</h1>
<p>Suppose a discrete random variable <span
class="math inline">\(X\)</span> of non-negative integer numbers, and
let <span
class="math inline">\(\lambda=\mu(x;\beta)=e^{x\beta}\geq0\)</span>.
Then we can say:</p>
<p><span class="math display">\[\begin{equation}
Y \sim Poisson(\mu(x,\beta))
\end{equation}\]</span></p>
<p>if:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
P(Y=y_i) &amp;= e^{-\lambda_i} \frac{\lambda_i^{y_i}}{y_i!}\\
&amp;= e^{-\mu(x_i,\beta)} \frac{\mu(x_i,\beta)^{y_i}}{y_i!}
\end{aligned}
\end{equation}\]</span></p>
<h1 id="expectation-and-variance">Expectation and Variance</h1>
<p>The expectation and the variation of Poisson distribution both
numerically equals to <span class="math inline">\(\lambda\)</span>:</p>
<p><span class="math display">\[\begin{equation}
\mathrm{E}(Y)=\mathrm{Var}(Y)=\lambda=\mu(x;\beta)
\end{equation}\]</span></p>
<h2 id="expectation">Expectation</h2>
<p>To proof:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
\mathrm{E}(Y) &amp;= \sum_{y=0}^{\infty}{y e^{-\lambda}
\frac{\lambda^{y}}{y!}} \\
&amp;= \sum_{y=1}^{\infty}{y e^{-\lambda} \frac{\lambda^{y}}{y!}} \\
&amp;= \sum_{y=1}^{\infty}{e^{-\lambda} \frac{\lambda^{y -
1}\lambda}{(y-1)!}} \\
&amp;= \lambda e^{-\lambda} \sum_{y=1}^{\infty}{\frac{\lambda^{y -
1}}{(y-1)!}}
\end{aligned}
\end{equation}\]</span></p>
<p>Based on the Taylor expansion:</p>
<p><span class="math display">\[\begin{equation}
e^x = 1 + x+\frac{x^2}{2!}+...+\frac{x^n}{n!}+... =
\sum_{k=1}^{\infty}{\frac{x^{k-1}}{(k-1)!}}
\end{equation}\]</span></p>
<p>We have:</p>
<p><span class="math display">\[\begin{equation}
\mathrm{E}(Y) = \lambda e^{-\lambda}
\sum_{y=1}^{\infty}{\frac{\lambda^{y - 1}}{(y-1)!}} = \lambda
e^{-\lambda} e^{\lambda} = \lambda
\end{equation}\]</span></p>
<h2 id="variance">Variance</h2>
<p>To compute the variance, we firstly compute the expectation of <span
class="math inline">\(Y^2\)</span>:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
\mathrm{E}(Y^2) &amp;= \sum_{y=0}^{\infty}{y^2 e^{-\lambda}
\frac{\lambda^y}{y!}} \\
&amp;= \lambda e^{-\lambda} \sum_{y=1}^{\infty}{\frac{y \lambda^{y -
1}}{(y-1)!}} \\
&amp;= \lambda e^{-\lambda} \sum_{y=1}^{\infty}{\frac{(y-1+1)\lambda^{y
- 1}}{(y-1)!}}
\end{aligned}
\end{equation}\]</span></p>
<p>Set <span class="math inline">\(m=k-1\)</span>, we have:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
\mathrm{E}(Y^2) &amp;= \lambda e^{-\lambda}(\sum_{m=0}^{\infty}{\frac{m
\lambda^m}{m!}} + \sum_{m=0}^{\infty}{\frac{\lambda^m}{m!}}) \\
&amp;= \lambda e^{-\lambda}(\lambda
\sum_{m=1}^{\infty}{\frac{\lambda^{m-1}}{(m-1)!}} +
\sum_{m=0}^{\infty}{\frac{\lambda^m}{m!}}) \\
&amp;= \lambda e^{-\lambda} (\lambda e^{\lambda} +e^{\lambda} ) =
\lambda(\lambda + 1)
\end{aligned}
\end{equation}\]</span></p>
<p>Finally, we can derive:</p>
<p><span class="math display">\[\begin{equation}
\mathrm{Var}(Y) = \mathrm{E}(Y^2) - (\mathrm{E}(Y))^2 = \lambda(\lambda
+ 1) - {\lambda}^2 = \lambda
\end{equation}\]</span></p>
<h1 id="log-likelihood">Log-Likelihood</h1>
<p>Then we can derive the likelihood of <span
class="math inline">\(Y\)</span> is:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
L(y;\beta) &amp;= \prod_{i=1}^{n}{P(Y=y_i)} \\
&amp;= \prod_{i=1}^{n}{e^{-\mu(x_i;\beta)}}\prod_{i=1}^n
\frac{\mu(x_i;\beta)^{y_i}}{y_i!}\\
&amp;=
e^{-\sum_{i=1}^{n}{\mu(x_i;\beta)}}\prod_{i=1}^{n}{\frac{\mu(x_i;\beta)^{y_i}}{y_i!}}
\end{aligned}
\end{equation}\]</span></p>
<p>Then, we can get the log-likelihood as:</p>
<p><span class="math display">\[\begin{equation}
\begin{aligned}
\ln{L(y;\beta)} &amp;=
-\sum_{i=1}^{n}{\mu(x_i;\beta)}+\sum_{i=1}^{n}{y_i
\ln{\mu(x_i;\beta)}}-\sum_{i=1}^{n}{\ln{y_i!}}\\
&amp;= -\sum_{i=1}^{n}{\mu(x_i;\beta)}+\sum_{i=1}^{n}{y_i
\ln{\mu(x_i;\beta)}} + const
\end{aligned}
\end{equation}\]</span></p>
<h1 id="poisson-regression">Poisson Regression</h1>
<p>We can learn the parameters <span
class="math inline">\(\beta\)</span> based on <em>MLE</em> to do
regression. The following codes are based on
<code>scipy.optimize.minimize</code>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> minimize <span class="keyword">as</span> mm</span><br><span class="line"></span><br><span class="line">N = <span class="number">10000</span>  <span class="comment"># number of data points</span></span><br><span class="line">P = <span class="number">5</span>  <span class="comment"># number of features</span></span><br><span class="line"></span><br><span class="line">X = np.random.randn(N, P)  <span class="comment"># matrix X in shape of NxP</span></span><br><span class="line">beta_real = np.random.randn(P)  <span class="comment"># the real values of \beta, in shape of P</span></span><br><span class="line">Y = np.random.poisson(np.exp(np.dot(X, beta_real)))  <span class="comment"># here, \lambda = exp(X\beta)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># The Poisson distribution of np.random.poisson(lam):</span></span><br><span class="line"><span class="comment"># f(k; lam) = (lam^k exp(-lam)) / (k!)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># loss function to maximize the loge-likelihood</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_function</span>(<span class="params">beta</span>):</span></span><br><span class="line">    Xbeta = np.dot(X, beta)</span><br><span class="line">    exp_Xbeta = np.exp(Xbeta)  <span class="comment"># \lambda = exp(X beta)</span></span><br><span class="line">    loss = exp_Xbeta.<span class="built_in">sum</span>() - np.dot(Y, Xbeta)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># optimize with scipy.optimize.minimize</span></span><br><span class="line">beta_ini = np.zeros(P)  <span class="comment"># initialize beta with zeros</span></span><br><span class="line">result = mm(loss_function, beta_ini)</span><br><span class="line">beta_predicted = result.x</span><br><span class="line"></span><br><span class="line"><span class="comment"># show results</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Real beta: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(beta_real))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Predicted beta: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(beta_predicted))</span><br></pre></td></tr></table></figure>
<p>The output of the above codes:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Real beta: [-<span class="number">0.40914376</span>  <span class="number">0.29649545</span>  <span class="number">0.59736634</span>  <span class="number">1.40512766</span> -<span class="number">0.55024536</span>]</span><br><span class="line">Predicted beta: [-<span class="number">0.40346132</span>  <span class="number">0.29799245</span>  <span class="number">0.60520007</span>  <span class="number">1.40263191</span> -<span class="number">0.54896361</span>]</span><br></pre></td></tr></table></figure>
<h1 id="main-reference">Main Reference:</h1>
<ul>
<li>Lecture slides by Claudia Czado: <a
href="https://www.groups.ma.tum.de/fileadmin/w00ccg/statistics/czado/lec6.pdf"
class="uri">https://www.groups.ma.tum.de/fileadmin/w00ccg/statistics/czado/lec6.pdf</a></li>
<li>Poisson distribution Wikipedia: <a
href="https://en.wikipedia.org/wiki/Poisson_distribution"
class="uri">https://en.wikipedia.org/wiki/Poisson_distribution</a></li>
<li>Poisson regression by <em>ahwillia</em>: <a
href="https://gist.github.com/ahwillia/40cdbe3b2f2df1806358dd1e6de0743a"
class="uri">https://gist.github.com/ahwillia/40cdbe3b2f2df1806358dd1e6de0743a</a></li>
</ul>
]]></content>
      <categories>
        <category>Probabilistic Machine Learning</category>
      </categories>
      <tags>
        <tag>Probability Theory</tag>
        <tag>Machine Learning</tag>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title>Negative Binomial Distribution - Expectation, Variance, Likelihood and Regression</title>
    <url>/2022/5-ProbabilisticML-2-NB/</url>
    <content><![CDATA[<p>This blog aims to show the detailed derivation of the expectation,
variance, likelihood and regression of <em>Negative Binomial
Distribution</em>.</p>
<p>The Poisson distribution can be generalized by including a gamma
noise variable, then we can get the negative binomial distribution.</p>
<span id="more"></span>
<h1 id="probability-density-formula">Probability Density Formula</h1>
<p><span class="math display">\[\begin{equation}
P(Y=y_i;\mu,\alpha) =
\frac{\Gamma(y_i+\alpha^{-1})}{\Gamma(y_i+1)\Gamma(\alpha^{-1})}(\frac{\alpha^{-1}}{\alpha^{-1}\mu})^{\alpha^{-1}}(\frac{\mu}{\alpha^{-1}+\mu})^{y_i}
\end{equation}\]</span></p>
<p>where: <span class="math display">\[\begin{equation}
\mu_i=e^{x_i\beta}
\end{equation}\]</span></p>
<p>We can set <span class="math inline">\(n=\alpha^{-1}\)</span> and
<span
class="math inline">\(p=\frac{\alpha^{-1}}{\alpha^{-1}+\mu}\)</span>,
then the above formula can be rewritten as:</p>
<p><span class="math display">\[\begin{equation}
P(Y=y_i;n,p) =
\frac{\Gamma(y_i+n)}{\Gamma(y_i+1)\Gamma(n)}p^n(1-p)^{y_i}
\end{equation}\]</span></p>
<h1 id="expectation-and-variance">Expectation and Variance</h1>
<p>The expectation and the variance is:</p>
<p><span class="math display">\[\begin{equation}
\mathrm{E}(Y) = \frac{n(1-p)}{p}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\mathrm{Var}(Y) = \frac{n(1-p)}{p^2}
\end{equation}\]</span></p>
<h2 id="expectation">Expectation</h2>
<p>To proof:</p>
<p><span class="math display">\[\begin{equation*}
\begin{aligned}
\mathrm{E}(Y) &amp; =
\sum_{y=0}^{\infty}{y\frac{(y+n-1)!}{(y)!(n-1)!}p^n(1-p)^{y}} \\
&amp;= \sum_{y=0}^{\infty}{\frac{(y+n-1)!}{(y-1)!(n-1)!}p^n(1-p)^y}\\
&amp;= \sum_{y=0}^{\infty}{\frac{(y+n-1)!}{y!n!}p^{n+1}(1-p)^{y-1}}\\
&amp;= \frac{n(1-p)}{p}
\sum_{y=1}^{\infty}{\frac{(y+n-1)!}{(y-1)!n!}p^{n+1}(1-p)^{y-1}} \\
&amp;= \frac{n(1-p)}{p}
\sum_{z=0}^{\infty}{\frac{((n+1)+z-1)!}{z!n!}p^{n+1}(1-p)^{z}}
\end{aligned}
\end{equation*}\]</span></p>
<p>As the integral sum of the negative binomial distribution is 1:</p>
<p><span class="math display">\[\begin{equation}
\sum_{z=0}^{\infty}{\frac{((n+1)+z-1)!}{z!n!}p^{n+1}(1-p)^{z}} = 1
\end{equation}\]</span></p>
<p>So, we can get:</p>
<p><span class="math display">\[\begin{equation}
\mathrm{E}(Y) = \frac{n(1-p)}{p}
\end{equation}\]</span></p>
<h2 id="variance">Variance</h2>
<p>Before we compute the variance, we firstly compute <span
class="math inline">\(\mathrm{E}(Y(Y-1))\)</span>:</p>
<p><span class="math display">\[\begin{equation*}
\begin{aligned}
\mathrm{E}(Y(Y-1)) &amp; =
\sum_{y=0}^{\infty}{y(y-1)\frac{(y+n-1)!}{y!(n-1)!}p^n(1-p)^y} \\
&amp;= \frac{n(r+1)(1-p)^2}{p^2}
\sum_{y=2}^{\infty}{\frac{((n+2)+(y-2)-1)!}{(y-2)!(n+1)!}p^{n+2}(1-p)^{y-2}}
\\
&amp;= \frac{n(r+1)(1-p)^2}{p^2}
\sum_{z=0}^{\infty}{\frac{((n+2)+z-1)!}{z!(n+1)!}p^{n+2}(1-p)^{z}} \\
&amp;= \frac{n(r+1)(1-p)^2}{p^2}
\end{aligned}
\end{equation*}\]</span></p>
<p>Then we can get:</p>
<p><span class="math display">\[\begin{equation}
E(Y^2) = E(Y(Y-1)) + E(Y) = \frac{n(n+1)(1-p)^2 + n(1-p)p}{p^2}
\end{equation}\]</span></p>
<p>Finally, we can compute the variance as:</p>
<p><span class="math display">\[\begin{equation}
\mathrm{Var}(Y) = \mathrm{E}(Y^2) - (\mathrm{E}(Y))^2 =
\frac{n(1-p)}{p^2}
\end{equation}\]</span></p>
<h1 id="log-likelihood">Log-Likelihood</h1>
<p>The log-likelihood that to maximize in an MLE approach is:</p>
<p><span class="math display">\[\begin{equation}
\sum_{i=1}^{n}{\ln(\Gamma(y_i+\alpha^{-1})) - \ln(\Gamma(\alpha^{-1})) -
\ln(\Gamma(y_i+1)) - (\alpha^{-1} + y_i)\ln(1+\alpha \mu_i)
+y_i(\ln(\alpha)+\ln(\mu_i))}
\end{equation}\]</span></p>
<h1 id="negative-binomial-regression">Negative Binomial Regression</h1>
<p>We can learn the parameters based on <em>MLE</em> to do regression.
The following codes are based on
<code>scipy.optimize.minimize</code>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> minimize <span class="keyword">as</span> mm</span><br><span class="line"><span class="keyword">from</span> scipy.special <span class="keyword">import</span> loggamma</span><br><span class="line"></span><br><span class="line">N = <span class="number">1000</span>  <span class="comment"># number of data points</span></span><br><span class="line">P = <span class="number">5</span>  <span class="comment"># number of features</span></span><br><span class="line"></span><br><span class="line">X = np.random.randn(N, P)  <span class="comment"># matrix X in shape of NxP</span></span><br><span class="line">alpha_real = np.random.randint(<span class="number">1</span>, <span class="number">10</span>)  <span class="comment"># the real values of \alpha, a scalar</span></span><br><span class="line">beta_real = np.random.randn(P)  <span class="comment"># the real values of \beta, in shape of P</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># To apply the np.random.negative_binomial function:</span></span><br><span class="line"><span class="comment"># n = 1 / alpha_real</span></span><br><span class="line"><span class="comment"># p = (1 / alpha_real) / ((1 / alpha_real) + exp(X * real_beta))</span></span><br><span class="line"></span><br><span class="line">n = <span class="number">1</span> / alpha_real</span><br><span class="line">p = n / (n + np.exp(np.dot(X, beta_real)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># The negative binomial distribution defined from np.random.negative_binomial(n,p):</span></span><br><span class="line"><span class="comment"># P(y; n, p) = ((y+n-1)!)/(y!(n-1)!) * (p^n) * (1-p)^y</span></span><br><span class="line">Y = np.random.negative_binomial(n, p)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># loss and gradient function</span></span><br><span class="line"><span class="comment"># params = [alpha, beta]</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_function</span>(<span class="params">params</span>):</span></span><br><span class="line">    alpha = params[<span class="number">0</span>]</span><br><span class="line">    beta = params[<span class="number">1</span>:]</span><br><span class="line">    mu = np.exp(np.dot(X, beta))</span><br><span class="line"></span><br><span class="line">    log_likelihood = loggamma(Y + <span class="number">1</span> / alpha).<span class="built_in">sum</span>() \</span><br><span class="line">                     - loggamma(alpha) * N \</span><br><span class="line">                     - loggamma(Y + <span class="number">1</span>).<span class="built_in">sum</span>() \</span><br><span class="line">                     - <span class="number">1</span> / alpha * (np.log(<span class="number">1</span> + alpha * mu).<span class="built_in">sum</span>()) \</span><br><span class="line">                     - np.dot(Y, np.log(<span class="number">1</span> + alpha * mu)) \</span><br><span class="line">                     + (Y * np.log(alpha)).<span class="built_in">sum</span>() \</span><br><span class="line">                     + np.dot(Y, np.log(mu))</span><br><span class="line">    <span class="keyword">return</span> -log_likelihood</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># optimize with scipy.optimize.minimize</span></span><br><span class="line">params_ini = np.ones(P + <span class="number">1</span>)  <span class="comment"># initialize params ([alpha, beta]) with zeros</span></span><br><span class="line">result = mm(loss_function, params_ini)</span><br><span class="line">params_predicted = result.x</span><br><span class="line"></span><br><span class="line"><span class="comment"># show results</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Real alpha: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(alpha_real))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Real beta: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(beta_real))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Predicted alpha: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(params_predicted[<span class="number">0</span>]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Predicted beta: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(params_predicted[<span class="number">1</span>:]))</span><br></pre></td></tr></table></figure>
<p>The output of the above codes:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Real alpha: <span class="number">2</span></span><br><span class="line">Real beta: [ <span class="number">1.6794512</span>  -<span class="number">0.22624054</span>  <span class="number">1.15579192</span>  <span class="number">0.35920843</span>  <span class="number">0.09326148</span>]</span><br><span class="line">Predicted alpha: <span class="number">2.0811572484796637</span></span><br><span class="line">Predicted beta: [ <span class="number">1.69292056</span> -<span class="number">0.28083378</span>  <span class="number">1.18706627</span>  <span class="number">0.43136325</span>  <span class="number">0.1085059</span> ]</span><br></pre></td></tr></table></figure>
<h1 id="main-reference">Main Reference:</h1>
<ul>
<li>Wikipedia of Negative binomial distribution: <a
href="https://en.wikipedia.org/wiki/Negative_binomial_distribution"
class="uri">https://en.wikipedia.org/wiki/Negative_binomial_distribution</a></li>
<li>Negative Binomial Distributio introduction: <a
href="http://www.math.ntu.edu.tw/~hchen/teaching/StatInference/notes/lecture16.pdf"
class="uri">http://www.math.ntu.edu.tw/~hchen/teaching/StatInference/notes/lecture16.pdf</a></li>
<li>Chapter 326 from NCSS Statistical Software: <a
href="https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Negative_Binomial_Regression.pdf"
class="uri">https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/NCSS/Negative_Binomial_Regression.pdf</a></li>
</ul>
]]></content>
      <categories>
        <category>Probabilistic Machine Learning</category>
      </categories>
      <tags>
        <tag>Probability Theory</tag>
        <tag>Machine Learning</tag>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title>A Brief Tutorial to Use PySC2 Learning Environment (Overview)</title>
    <url>/2022/1-tutorial-pysc2-1/</url>
    <content><![CDATA[<p><code>PySC2</code> is DeepMind's Python component of the StarCraft II
Learning Environment (SC2LE). This is a brief tutorial about how to use
the interface as an interactable environment. You can also refer to the
<a href="https://github.com/mhz2180572509/HowToUsePySC2/">repo on
GitHub</a>.</p>
<span id="more"></span>
<h1 id="installation">Installation</h1>
<p><strong>It's strongly recommended to use virtual environments to
manage packages.</strong></p>
<p>You may need to run <code>pip install --upgrade pip</code> before all
the following steps.</p>
<h2 id="install-on-windows">Install on Windows</h2>
<ul>
<li><p>Get <code>PySC2</code></p>
<p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pip install pysc2</span><br></pre></td></tr></table></figure> <strong>Not recommended unless you need:</strong>
download from source, please refer to: <a
href="https://github.com/deepmind/pysc2#from-source"
class="uri">https://github.com/deepmind/pysc2#from-source</a></p></li>
<li><p>Get <em>StarCraft II</em> game</p>
<ul>
<li>Download from Blizzard official network: <a
href="https://starcraft2.com/"
class="uri">https://starcraft2.com/</a>.</li>
<li>You can firstly install the Battle.net Agent/Desktop and install the
StarCraft II game in the game launcher: <a
href="https://www.blizzard.com/en-us/apps/battle.net/desktop"
class="uri">https://www.blizzard.com/en-us/apps/battle.net/desktop</a></li>
<li>If you customized the install-location, you might need to set the
<code>SC2PATH</code> environment variable with your new location.</li>
</ul></li>
<li><p>Get maps</p>
<p>Create a folder named <code>Maps</code> in the game root folder. Then
download the maps and mini-maps and extract them into <code>Maps</code>.
You can start from the mini-games. For example, after you extract the
maps in the folder, the path should be like this:
<code>GameFolder/Maps/Melee/XXX.SC2Map</code>.</p>
<ul>
<li>All map packs: <a
href="https://github.com/Blizzard/s2client-proto#downloads"
class="uri">https://github.com/Blizzard/s2client-proto#downloads</a></li>
<li>Mini-games: <a
href="https://github.com/deepmind/pysc2/releases/download/v1.2/mini_games.zip"
class="uri">https://github.com/deepmind/pysc2/releases/download/v1.2/mini_games.zip</a></li>
<li>Melee maps: <a
href="http://blzdistsc2-a.akamaihd.net/MapPacks/Melee.zip"
class="uri">http://blzdistsc2-a.akamaihd.net/MapPacks/Melee.zip</a></li>
</ul>
<p>The password to extract the packages is
<strong>iagreetotheeula</strong></p></li>
</ul>
<h2 id="install-on-linux">Install on Linux</h2>
<ul>
<li>Install <code>PySC2</code>: <code>pip install pysc2</code></li>
<li>Install StarCraft II game:
<ul>
<li>Download the linux package: <a
href="https://github.com/Blizzard/s2client-proto/blob/master/README.md#linux-packages"
class="uri">https://github.com/Blizzard/s2client-proto/blob/master/README.md#linux-packages</a>
<ul>
<li>Can using the command: <code>wget
http://blzdistsc2-a.akamaihd.net/Linux/SC2.4.10.zip</code></li>
</ul></li>
<li>Unzip the file at the home path: <code>unzip -o SC.X.X.zip</code>
<ul>
<li>The password is <strong>iagreetotheeula</strong></li>
</ul></li>
<li>It seems that the maps are already included in the
<code>[StarCraftII]/Maps/</code> folder, if you need to install the
replays, you need to download and unzip them into the
<code>[StarCraftII]/Replays/</code> folder manually.</li>
</ul></li>
</ul>
<h1 id="run-some-built-in-examples">Run Some Built-in Examples</h1>
<ul>
<li>Run the built-in agent example: <code>python -m pysc2.bin.agent
--map Simple64</code></li>
<li>Run your own agent: <code>python -m pysc2.bin.agent --map
CollectMineralShards --agent
pysc2.agents.scripted_agent.CollectMineralShards</code>
<ul>
<li>Will have more detailed instructions to write and run our
self-defined agents later.</li>
</ul></li>
<li>Run two agents against each other <code>python -m pysc2.bin.agent
--map Simple64 --agent2
pysc2.agents.random_agent.RandomAgent</code></li>
<li>Play the games as a human: <code>python -m pysc2.bin.play --map
Simple64</code></li>
<li>List the maps: <code>python -m pysc2.bin.map_list</code></li>
<li>Watch the replay: <code>python -m pysc2.bin.play --replay
&lt;path-to-replay&gt;</code>
<ul>
<li>Running an agent and playing as a human save a replay by default.
You can watch that replay by running the above command.</li>
</ul></li>
</ul>
<h1 id="official-doc-of-pysc2-and-useful-links">Official Doc of PySC2
and Useful Links</h1>
<ul>
<li>Before we start, it's very <strong>important</strong> to read the
official document from <code>PySC2</code>: <a
href="https://github.com/deepmind/pysc2/blob/master/docs/environment.md"
class="uri">https://github.com/deepmind/pysc2/blob/master/docs/environment.md</a>
<ul>
<li>You can briefly know about (but you may still be very confused
with): the structure of <code>pysc2</code>, the observations and actions
provided by <code>pysc2</code>, the environment for reinforcement
learning, and so on.</li>
</ul></li>
<li>Introductions to the mini-games (read it when you need): <a
href="https://github.com/deepmind/pysc2/blob/master/docs/mini_games.md"
class="uri">https://github.com/deepmind/pysc2/blob/master/docs/mini_games.md</a></li>
</ul>
<h1 id="start-to-use-pysc2">Start to Use PySC2</h1>
<h2 id="approach-1">Approach 1</h2>
<p>In thie approach, you can only customize the agent, and run the agent
by running the above commands.</p>
<ul>
<li>In this approach, your agent gets observation from the environment
and returns actions to interact with it.</li>
<li>You need to run the agent using the built-in module
<code>pysc2.bib.agent</code></li>
<li>It's hard to realize a learning agent.</li>
<li>It's a good way to start to know about the environment.</li>
<li>Detailed instructions at <a href="/2022/2-tutorial-pysc2-2/" title="Use PySC2 Learning Environment - Define Your Own Agent">Use PySC2 Learning Environment - Define Your Own Agent</a> and <a
href="https://github.com/mhz2180572509/HowToUsePySC2/blob/main/Approach_1.py">example
codes</a>.</li>
</ul>
<h2 id="approach-2">Approach 2</h2>
<p>In thie approach, you can customize both the environment and the
agent, run your codes independently without any built-in modules. * More
flexible. * Can define our logics in your agent, like learning and doing
inference. * Can run the codes directly without any built-in modules. *
Can debug easily. * Detailed instructions at <a href="/2022/3-tutorial-pysc2-3/" title="Use PySC2 Learning Environment - Control Your Own Environment and Agent">Use PySC2 Learning Environment - Control Your Own Environment and Agent</a> and <a
href="https://github.com/mhz2180572509/HowToUsePySC2/blob/main/Approach_2.py">example
codes</a>.</p>
<h1 id="main-reference">Main Reference</h1>
<ul>
<li>PySC2 introduction and documents by DeepMind: <a
href="https://github.com/deepmind/pysc2"
class="uri">https://github.com/deepmind/pysc2</a></li>
</ul>
]]></content>
      <categories>
        <category>Tutorial</category>
      </categories>
      <tags>
        <tag>Reinforcement Learning</tag>
        <tag>PySC2</tag>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>First Order AutoRegression (AR(1)) - Expectation, Variance, Likelihood and Regression</title>
    <url>/2022/6-ProbabilisticML-3-AR1/</url>
    <content><![CDATA[<p>This blog aims to show the detailed derivation of the expectation,
variance, likelihood and regression of <em>First-order autoregression
(AR(1))</em> model.</p>
<span id="more"></span>
<h1 id="probability-density-formula">Probability Density Formula</h1>
<p>The <em>first-order autoregression</em> (<em>AR(1)</em>) can model
(weakly) stationary time series, if the series <span
class="math inline">\(x_t\)</span> satisfy the following properties:</p>
<ul>
<li>The mean <span class="math inline">\(\mathrm{E}(x_t)\)</span> is the
same for all <span class="math inline">\(t\)</span>.</li>
<li>The variance <span class="math inline">\(\mathrm{Var}(x_t)\)</span>
is the same for all <span class="math inline">\(t\)</span>.</li>
<li>The covariance (and also correlation) between <span
class="math inline">\(x_t\)</span> and <span
class="math inline">\(x_{t-h}\)</span> is the same for all <span
class="math inline">\(t\)</span> at each lag <span
class="math inline">\(h=1,2,3\)</span>, etc.</li>
</ul>
<p>In the first-order autoregression model, the value of <span
class="math inline">\(x\)</span> at time <span
class="math inline">\(t\)</span> is a linear function of the value of
<span class="math inline">\(x\)</span> at time <span
class="math inline">\(t-1\)</span>, which can be written as:</p>
<p><span class="math display">\[\begin{equation}
x_t = \delta + \phi x_{t-1} + \omega_t
\end{equation}\]</span></p>
<p>with the following assumptions:</p>
<ul>
<li><span class="math inline">\(\omega_t \backsim
N(0,\sigma_{\omega}^2)\)</span> i.i.d..</li>
<li>Properties of the errors <span
class="math inline">\(\omega_t\)</span> are independent of <span
class="math inline">\(x_t\)</span>.</li>
<li>The series <span class="math inline">\(x_t\)</span> is (weakly)
stationary, which requires <span class="math inline">\(|\phi|\ &lt;
1\)</span>.</li>
</ul>
<h1 id="expectation-and-variance">Expectation and Variance</h1>
<h2 id="expectation">Expectation</h2>
<p>The expectation of AR(1) model is:</p>
<p><span class="math display">\[\begin{equation}
\mathrm{E}(x_t)=\frac{\delta}{1-\phi}
\end{equation}\]</span></p>
<p>To proof:</p>
<p><span class="math display">\[\begin{equation}
\mathrm{E}(x_t)=\mathrm{E}(\delta + \phi x_{t-1} +
\omega_t)=\mathrm{E}(\delta) + \mathrm{E}(\phi x_{t-1})+
\mathrm{E}(\omega_t) = \delta + \phi \mathrm{E}(x_{t-1})
\end{equation}\]</span></p>
<p>With the stationary assumption, <span
class="math inline">\(\mathrm{E}(x_t) = \mathrm{E}(x_{t-1})\)</span>, we
can solve the equation to get:</p>
<p><span class="math display">\[\begin{equation}
\mathrm{E}(x_t)=\frac{\delta}{1-\phi}
\end{equation}\]</span>.</p>
<h2 id="variance">Variance</h2>
<p>The variance of AR(1) model is:</p>
<p><span class="math display">\[\begin{equation}
\mathrm{Var}(x_t)=\frac{\sigma_{\omega}^2}{1-\phi^2}
\end{equation}\]</span></p>
<p>To proof:</p>
<p><span class="math display">\[\begin{equation}
\mathrm{Var}(x_t)=\mathrm{Var}(\delta) + \mathrm{Var}(\phi x_{t-1})+
\mathrm{Var}(\omega_t) = \phi^2 \mathrm{Var}(x_{t-1}) +
\sigma_{\omega}^2
\end{equation}\]</span></p>
<p>With the stationary assumption, <span
class="math inline">\(\mathrm{Var}(x_t) =
\mathrm{Var}(x_{t-1})\)</span>, we can solve the equation to get:</p>
<p><span class="math display">\[\begin{equation}
\mathrm{Var}(x_t)=\frac{\sigma_{\omega}^2}{1-\phi^2}
\end{equation}\]</span>.</p>
<h1 id="log-likelihood">Log-Likelihood</h1>
<p>In this part, we will derive the log-likelihood of the AR(1) model,
which can be used to estimate the parameters in the MLE approach.</p>
<p>Firstly, we define the parameters: <span class="math inline">\(\theta
= (\delta,\phi,\sigma_{\omega}^2)\)</span>.</p>
<p>Based on the Bayesian theory:</p>
<p><span class="math display">\[\begin{equation}
P(x_t,x_{t-1},...,x_1;\theta) =
P(x_t|x_{t-1},x_{t-2},...,x_1;\theta)P(x_{t-1}|x_{t-2},...,x_1;\theta)...P(x_2|x_1;\theta)P(x_1;\theta)
\end{equation}\]</span></p>
<p>As in the AR(1) model, we assume that the <span
class="math inline">\(x_t\)</span> only directly conditional on <span
class="math inline">\(x_{t-1}\)</span>, then the above equation can be
simplified as:</p>
<p><span class="math display">\[\begin{equation}
P(x_t,x_{t-1},...,x_1;\theta) =
P(x_t|x_{t-1};\theta)P(x_{t-1}|x_{t-2};\theta)...P(x_2|x_1;\theta)P(x_1;\theta)
\end{equation}\]</span></p>
<p>Then we can rewrite the log-likelihood as:</p>
<p><span class="math display">\[\begin{equation}
\ln{L(\theta|x)} =\sum_{t=2}^{T}{\ln{P(x_t|x_{t-1};\theta)}} +
\ln{P(x_1;\theta)}
\end{equation}\]</span></p>
<p>Secondly, consider the (weakly) stationary AR(1) model, we have:</p>
<p><span class="math display">\[\begin{equation}
x_t = \delta + \phi x_{t-1} + \omega_t
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\omega_t \backsim i.i.d.
N(0,\sigma_{\omega}^2)\)</span> and <span
class="math inline">\(|\phi|&lt;1\)</span>.</p>
<p>Based on this, we can rewrite it as:</p>
<p><span class="math display">\[\begin{equation}
x_t|x_{t-1} \backsim N(\delta +\phi x_{t-1},\sigma_{\omega}^2)
\end{equation}\]</span></p>
<p>which equals to:</p>
<p><span class="math display">\[\begin{equation}
P(x_t|x_{t-1};\theta) =
\frac{1}{\sqrt{2\pi}\sigma_{\omega}}e^{-\frac{1}{2\sigma_{\omega}^2}(x_t-\delta-\phi
x_{t-1})^2}
\end{equation}\]</span></p>
<p>Then we can derive:</p>
<p><span class="math display">\[\begin{equation*}
\begin{aligned}
\sum_{t=2}^{T}{\ln{P(x_t|x_{t-1};\theta)}} &amp;=
\sum_{t=2}^{T}{-\frac{1}{2}\ln{2\pi
\sigma_{\omega}^2}-\frac{1}{2\sigma_{\omega}^2}(x_t-\delta-\phi
x_{t-1})^2} \\
&amp;=
-\frac{T-1}{2}\ln{2\pi}-\frac{T-1}{2}\ln{\sigma_{\omega}^2}-\frac{1}{2\sigma_{\omega}^2}\sum_{t=2}^{T}{(x_t-\delta-\phi
x_{t-1})^2}
\end{aligned}
\end{equation*}\]</span></p>
<p>Next, we have proven that for all <span
class="math inline">\(t\in{1,2,...,T}\)</span>, the expectation and
variance of <span class="math inline">\(x_t\)</span> is
respectively:</p>
<p><span class="math display">\[\begin{equation}
\mathrm{E}(x_t)=\frac{\delta}{1-\phi}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\mathrm{Var}(x_t)=\frac{\sigma_{\omega}^2}{1-\phi^2}
\end{equation}\]</span></p>
<p>So for <span class="math inline">\(x_1\)</span>, we have:</p>
<p><span class="math display">\[\begin{equation}
x_1 \backsim N(\frac{\delta}{1-\phi},\frac{\sigma_{\omega}^2}{1-\phi^2})
\end{equation}\]</span></p>
<p>which equals to:</p>
<p><span class="math display">\[\begin{equation}
P(x_1;\theta) =
\frac{\sqrt{1-\phi^2}}{\sqrt{2\pi}\sigma_{\omega}}e^{-\frac{1-\phi^2}{2\sigma_{\omega}^2}(x_1-\frac{\delta}{1-\phi})^2}
\end{equation}\]</span></p>
<p>Then we can derive:</p>
<p><span class="math display">\[\begin{equation}
\ln{P(x_1;\theta)} =
-\frac{1}{2}\ln{2\pi}-\frac{1}{2}\ln{\frac{\delta^2}{1-\phi^2}}-\frac{1-\phi^2}{2\sigma_{\omega}^2}(x_1-\frac{\delta}{1-\phi})^2
\end{equation}\]</span></p>
<p>Finally we can have the log-likelihood as:</p>
<p><span class="math display">\[\begin{equation*}
\begin{aligned}
\ln{L(\theta|x)} &amp;= \sum_{t=2}^{T}{\ln{P(x_t|x_{t-1};\theta)}} +
\ln{P(x_1;\theta)}\\
&amp;= -\frac{T}{2}\ln{2\pi} - \frac{1}{2}
\ln{\frac{\sigma_{\omega}^2}{1-\phi^2}}-\frac{1-\phi^2}{2\sigma_{\omega}^2}(x_1-\frac{\delta}{1-\phi})^2-\frac{T-1}{2}\ln{\sigma_{\omega}^2}-\frac{1}{2\sigma_{\omega}^2}\sum_{t=2}^{T}{(x_t-\delta-\phi
x_{t-1})^2}
\end{aligned}
\end{equation*}\]</span></p>
<h1 id="mle-regression">MLE Regression</h1>
<p>We can learn the parameters based on <em>MLE</em> to do regression.
The following codes are based on
<code>scipy.optimize.minimize</code>:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> minimize <span class="keyword">as</span> mm</span><br><span class="line"></span><br><span class="line">theta_real = [<span class="number">5</span>, <span class="number">0.6</span>, <span class="number">1</span>]  <span class="comment"># parameters \theta is defined as [\delta, \phi, \sigma]</span></span><br><span class="line">expectation_real = theta_real[<span class="number">0</span>] / (<span class="number">1</span> - theta_real[<span class="number">1</span>])  <span class="comment"># expectation</span></span><br><span class="line">variance_real = theta_real[<span class="number">2</span>] ** <span class="number">2</span> / (<span class="number">1</span> - theta_real[<span class="number">1</span>] ** <span class="number">2</span>)  <span class="comment"># variance</span></span><br><span class="line"></span><br><span class="line">T = <span class="number">100</span>  <span class="comment"># number of time points</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># generate x_1</span></span><br><span class="line">x_1 = np.random.normal(expectation_real, variance_real)</span><br><span class="line"><span class="comment"># generate x_t, t=2,3,...,T</span></span><br><span class="line">data = [x_1]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(T - <span class="number">1</span>):</span><br><span class="line">    x_next = theta_real[<span class="number">0</span>] + theta_real[<span class="number">1</span>] * data[-<span class="number">1</span>] + np.random.normal(<span class="number">0</span>, theta_real[<span class="number">2</span>] ** <span class="number">2</span>)</span><br><span class="line">    data.append(x_next)</span><br><span class="line"></span><br><span class="line">data = np.array(data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># loss function (negative of log-likelihood)</span></span><br><span class="line"><span class="comment"># params: \theta = [\delta, \phi, \sigma]</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_function</span>(<span class="params">params</span>):</span></span><br><span class="line">    <span class="keyword">assert</span> <span class="built_in">len</span>(params) == <span class="number">3</span>, <span class="string">&quot;incorrect shape of parameters&quot;</span></span><br><span class="line">    delta, phi, sigma = params</span><br><span class="line"></span><br><span class="line">    x_t = data[<span class="number">1</span>:]</span><br><span class="line">    x_t_1 = data[:-<span class="number">1</span>]</span><br><span class="line">    sum_2_T = np.<span class="built_in">sum</span>((x_t - delta - phi * x_t_1) ** <span class="number">2</span>)</span><br><span class="line">    log_likelihood = - <span class="number">0.5</span> * T * np.log(<span class="number">2</span> * <span class="number">3.14</span>) \</span><br><span class="line">                     - <span class="number">0.5</span> * np.log(sigma ** <span class="number">2</span> / (<span class="number">1</span> - phi ** <span class="number">2</span>)) \</span><br><span class="line">                     - <span class="number">0.5</span> * (<span class="number">1</span> - phi ** <span class="number">2</span>) / (sigma ** <span class="number">2</span>) * ((x_1 - delta / (<span class="number">1</span> - phi)) ** <span class="number">2</span>) \</span><br><span class="line">                     - (T - <span class="number">1</span>) / <span class="number">2</span> * np.log(sigma ** <span class="number">2</span>) \</span><br><span class="line">                     - <span class="number">0.5</span> / (sigma ** <span class="number">2</span>) * sum_2_T</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> -log_likelihood</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># optimize with scipy.optimize.minimize</span></span><br><span class="line">params_ini = np.random.rand(<span class="number">3</span>)  <span class="comment"># initialize params ([\delta, \phi, \sigma])</span></span><br><span class="line">params_bounds = ((<span class="number">0</span>, <span class="number">10</span>), (<span class="number">0</span>, <span class="number">1</span>), (<span class="number">0</span>, <span class="number">2</span>))  <span class="comment"># set some boundaries for the parameters</span></span><br><span class="line">result = mm(loss_function, params_ini, bounds=params_bounds, method=<span class="string">&#x27;Powell&#x27;</span>, tol=<span class="number">1e-10</span>)</span><br><span class="line">params_predicted = result.x</span><br><span class="line"></span><br><span class="line"><span class="comment"># show results</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Real parameters [\delta, \phi, \sigma]: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(theta_real))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Predicted parameters [\delta, \phi, \sigma]: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(params_predicted))</span><br></pre></td></tr></table></figure>
<p>One of the results of the above codes is:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">Real parameters [\delta, \phi, \sigma]: [<span class="number">5</span>, <span class="number">0.6</span>, <span class="number">1</span>]</span><br><span class="line">Predicted parameters [\delta, \phi, \sigma]: [<span class="number">4.84142903</span> <span class="number">0.60249039</span> <span class="number">1.0670589</span>]</span><br></pre></td></tr></table></figure>
<h1 id="main-reference">Main Reference:</h1>
<ul>
<li>STAT 510 Course (1.1 &amp; 1.2) of Eberly College of Science of
*PennState: <a href="https://online.stat.psu.edu/stat510/lesson/1"
class="uri">https://online.stat.psu.edu/stat510/lesson/1</a></li>
<li>Estimation of ARMA Models by Eric Zivot: <a
href="https://faculty.washington.edu/ezivot/econ584/notes/armaestimation.pdf"
class="uri">https://faculty.washington.edu/ezivot/econ584/notes/armaestimation.pdf</a></li>
</ul>
]]></content>
      <categories>
        <category>Probabilistic Machine Learning</category>
      </categories>
      <tags>
        <tag>Probability Theory</tag>
        <tag>Machine Learning</tag>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title>Use PySC2 Learning Environment - Control Your Own Environment and Agent</title>
    <url>/2022/3-tutorial-pysc2-3/</url>
    <content><![CDATA[<p>This is a brief introduction to an more comprehensive approach to use
the <code>PySC2</code> by defining both your own environment and agent,
and you can also control the interaction between the agent and the
environment. A basic template can be found <a
href="https://github.com/mhz2180572509/HowToUsePySC2/blob/main/Approach_2.py">here</a>.
(The codes are also attached at the end).</p>
<ul>
<li>For an overview of <code>PySC2</code>, you can proceed to
<a href="/2022/1-tutorial-pysc2-1/" title="A Brief Tutorial to Use PySC2 Learning Environment (Overview)">A Brief Tutorial to Use PySC2 Learning Environment (Overview)</a>.</li>
<li>For an simpler approach to only define your own agent, you can
proceed to <a href="/2022/2-tutorial-pysc2-2/" title="Use PySC2 Learning Environment - Define Your Own Agent">Use PySC2 Learning Environment - Define Your Own Agent</a></li>
</ul>
<span id="more"></span>
<p>The environment of PySC2 is defined in
<code>pysc2.env.sc2_env</code>, while the actions and observations are
defined in <code>pysc2.lib.features</code>. The class of
<code>PySC2</code> environment is <code>SC2Env</code>, which Inherits
from <code>pysc2.env.environment.Base</code>. <strong>You can use the
<code>SC2Env</code> just like any other <em>OpenAI Gym</em>
environments.</strong></p>
<p>A basic template to instantiate the environment and an agent, and run
the codes to make the agent interact with the environment can be found
<a
href="https://github.com/mhz2180572509/HowToUsePySC2/blob/main/Approach_1.py">here</a>.</p>
<h1 id="to-instantiate-an-environment">To Instantiate An
Environment</h1>
<p>Import the <code>SC2Env</code> from <code>pysc2.env.sc2_env</code>
and instantiate it by <code>env = SC2Env([parameters])</code>.</p>
<p>The definition of the class and all its parameters can be found <a
href="https://github.com/deepmind/pysc2/blob/master/pysc2/env/sc2_env.py#L121">here</a>.</p>
<p>Some important arguments:</p>
<ul>
<li><code>map_name</code>: the name of the map.
<ul>
<li>You can find the namelist in <code>pysc2.bin.map_list</code> or by
running <code>python -m pysc2.bin.map_list</code></li>
<li>Or you can find them under the <code>pysc2/maps/</code> folder, like
the script <code>pysc2/maps/melee.py</code> lists all the maps of
<em>Melee</em>: <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">melee_maps = [&quot;Flat32&quot;, &quot;Flat48&quot;, &quot;Flat64&quot;, &quot;Flat96&quot;, &quot;Flat128&quot;, &quot;Simple64&quot;, &quot;Simple96&quot;, &quot;Simple128&quot;,]</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li><code>players</code>：a list, containing one or two instances of
<code>pysc2.env.sc2_env.Agent</code> or
<code>pysc2.env.sc2_env.Bot</code>, some maps only allow one agent.
<ul>
<li>Note: the <code>Agent</code> and <code>Bot</code> is different from
the <code>pysc2.agents.base_agent</code> we mentioned before, here is an
example for these two classes: <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Agent</span>(<span class="params">collections.namedtuple(<span class="params"><span class="string">&quot;Agent&quot;</span>, [<span class="string">&quot;race&quot;</span>, <span class="string">&quot;name&quot;</span>]</span>)</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Define an Agent. It can have a single race or a list of races.&quot;&quot;&quot;</span></span><br><span class="line">	</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__new__</span>(<span class="params">cls, race, name=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>(Agent, cls).__new__(cls, to_list(race), name <span class="keyword">or</span> <span class="string">&quot;&lt;unknown&gt;&quot;</span>)</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Bot</span>(<span class="params">collections.namedtuple(<span class="params"><span class="string">&quot;Bot&quot;</span>, [<span class="string">&quot;race&quot;</span>, <span class="string">&quot;difficulty&quot;</span>, <span class="string">&quot;build&quot;</span>]</span>)</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Define a Bot. It can have a single or list of races or builds.&quot;&quot;&quot;</span></span><br><span class="line">	</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__new__</span>(<span class="params">cls, race, difficulty, build=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>(Bot, cls).__new__(cls, to_list(race), difficulty, to_list(build <span class="keyword">or</span> BotBuild.random))</span><br></pre></td></tr></table></figure></li>
</ul></li>
<li><code>agent_interface_format</code>: to define the format of
observation and action, like the resolution of the feature maps. It
takes an instance of
<code>pysc2.lib.features.AgentInterfaceFormat</code> or an instance of
<code>pysc2.env.sc2_env.AgentInterfaceFormat</code>.
<ul>
<li>The number of <code>AgentInterfaceFormat</code> should be the same
as the length of the list for the above <code>player</code> argument,
with the same order.</li>
<li>Please refer to <a
href="https://github.com/deepmind/pysc2/blob/master/pysc2/lib/features.py#L470">the
definition</a> of <code>AgentInterfaceFormat</code> for more
details.</li>
</ul></li>
<li><code>step_mul</code>: an int to identify after how many steps to
take one observation and apply one action. (not the real number of
frames). 1 second equals to 16 steps, which means if we set 16 here, we
will get the observations every 1 second.</li>
<li><code>game_steps_per_episode</code>: how many steps of one episode.
For example, if we set <code>200*16</code> here, it means one episode
will last for 200 seconds.</li>
<li><code>save_replay_episodes</code>: how many episodes to save one
replay.</li>
<li><code>replay_dir</code>: the location to save replays.</li>
</ul>
<h1 id="define-a-function-to-interact-with-the-environment">Define A
Function to Interact with The Environment</h1>
<p>To define a function to interact with the environment, you can refer
to the <code>run_loop</code> function in <a
href="https://github.com/deepmind/pysc2/blob/master/pysc2/env/run_loop.py#L23">pysc2/env/run_loop.py</a></p>
<p>Here is also a good reference to instantiate an <code>SC2Env</code>
and an <code>Agent</code>, and use the above <code>run_loop</code>
function to test them in <a
href="https://github.com/deepmind/pysc2/blob/master/pysc2/tests/easy_scripted_test.py">pysc2/tests/easy_scripted_test.py</a>.</p>
<h1 id="run-the-program">Run the Program</h1>
<p>To actually run the codes above, we need the <code>run</code>
function in <code>absl.app</code> package. The function takes in our
running function as a parameter, like this:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> pysc2.env <span class="keyword">import</span> run_loop, sc2_env</span><br><span class="line"><span class="keyword">from</span> pysc2.agents <span class="keyword">import</span> random_agent</span><br><span class="line"><span class="keyword">from</span> absl <span class="keyword">import</span> app</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">args</span>):</span></span><br><span class="line">    agent = random_agent.RandomAgent()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> sc2_env.SC2Env(map_name=<span class="string">&quot;MoveToBeacon&quot;</span>, </span><br><span class="line">	                players=[sc2_env.Agent(sc2_env.Race.terran)],</span><br><span class="line">			agent_interface_format=sc2_env.AgentInterfaceFormat(feature_dimensions=sc2_env.Dimensions(screen=<span class="number">84</span>, minimap=<span class="number">64</span>)), </span><br><span class="line">			step_mul=<span class="number">16</span>,</span><br><span class="line">			game_steps_per_episode=<span class="number">200</span> * <span class="number">16</span>, </span><br><span class="line">			visualize=<span class="literal">True</span>) <span class="keyword">as</span> env:</span><br><span class="line">	run_loop.run_loop([agent], env, <span class="number">200</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    app.run(main)</span><br></pre></td></tr></table></figure>
<p><strong>Notes</strong>: When we define the <code>main</code>
function, it must have at lest one argument, like <code>args</code>
here. You may not use it, but you have to define it.</p>
<h1 id="template-codes">Template Codes</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">A template  for approach 2.</span></span><br><span class="line"><span class="string">Agent: using the random agent, referring to: pysc2.agent.random_agent.RandomAgent</span></span><br><span class="line"><span class="string">Environment: using the &#x27;Simple64&#x27; environment, both the player and the build-in AI are the race of terran.</span></span><br><span class="line"><span class="string">You can simply run the agent in the environment by the command:</span></span><br><span class="line"><span class="string">    python Approach_2.py</span></span><br><span class="line"><span class="string">Or you can use the `pysc2.bin.agent` module to run the MyAgent individually like the approach 1:</span></span><br><span class="line"><span class="string">    python -m pysc2.bin.agent --map &lt;MAP_NAME&gt; --agent Approach_2.MyAgent</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment"># import the BaseAgent class which we should derive from</span></span><br><span class="line"><span class="keyword">from</span> pysc2.agents <span class="keyword">import</span> base_agent</span><br><span class="line"><span class="comment"># import actions</span></span><br><span class="line"><span class="keyword">from</span> pysc2.lib <span class="keyword">import</span> actions</span><br><span class="line"><span class="comment"># import features</span></span><br><span class="line"><span class="keyword">from</span> pysc2.lib.features <span class="keyword">import</span> AgentInterfaceFormat, Dimensions</span><br><span class="line"><span class="comment"># import the SC2Env environment</span></span><br><span class="line"><span class="keyword">from</span> pysc2.env.sc2_env <span class="keyword">import</span> SC2Env, Agent, Bot, Race, Difficulty</span><br><span class="line"><span class="comment"># import absl</span></span><br><span class="line"><span class="keyword">from</span> absl <span class="keyword">import</span> app</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># define the agent, overriding the `step` function</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyAgent</span>(<span class="params">base_agent.BaseAgent</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    My customized agent, simply copied from `pysc2.agents.random_agent.RandomAgent`.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span>(<span class="params">self, obs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MyAgent, self).step(obs)</span><br><span class="line">        function_id = np.random.choice(obs.observation.available_actions)</span><br><span class="line">        args = [[np.random.randint(<span class="number">0</span>, size) <span class="keyword">for</span> size <span class="keyword">in</span> arg.sizes] <span class="keyword">for</span> arg <span class="keyword">in</span></span><br><span class="line">                self.action_spec.functions[function_id].args]</span><br><span class="line">        <span class="keyword">return</span> actions.FunctionCall(function_id, args)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># define a loop function for only one agent</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loop</span>(<span class="params">agent, env, max_steps=<span class="number">200</span></span>):</span></span><br><span class="line">    <span class="comment"># Set up the agent</span></span><br><span class="line">    <span class="comment"># ! Important: here, to setup the agent, the `env.observation_spec()` and `env.action_spec()` return tuples,</span></span><br><span class="line">    <span class="comment"># ! however, we want the elements inside, so we need the indexes `[0]` form them respectively.</span></span><br><span class="line">    observation_spec = env.observation_spec()[<span class="number">0</span>]</span><br><span class="line">    action_spec = env.action_spec()[<span class="number">0</span>]</span><br><span class="line">    agent.setup(observation_spec, action_spec)</span><br><span class="line">    <span class="comment"># reset the environment and the agent</span></span><br><span class="line">    <span class="comment"># ! Note: the `env.reset()` returns a tuple,</span></span><br><span class="line">    <span class="comment"># ? each element for each agent/bot.</span></span><br><span class="line">    timesteps = env.reset()</span><br><span class="line">    agent.reset()</span><br><span class="line">    total_steps = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># ! Note: the `env.step()` function needs a list, which actually allows multiple actions per frame,</span></span><br><span class="line">        <span class="comment"># ! so, we need to pack up the single action returned by the `agent.step()` function.</span></span><br><span class="line">        <span class="comment"># ! However, if the `agent.step()` function returns a list itself, then there is no need to use the list.</span></span><br><span class="line">        action = [agent.step(timesteps[<span class="number">0</span>])]</span><br><span class="line">        <span class="keyword">if</span> timesteps[<span class="number">0</span>].last():</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        total_steps += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> total_steps &gt; max_steps:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        timesteps = env.step(action)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># define the main function</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">args</span>):</span></span><br><span class="line">    agent = MyAgent()</span><br><span class="line">    <span class="comment"># define the environment</span></span><br><span class="line">    env = SC2Env(map_name=<span class="string">&quot;Simple64&quot;</span>,</span><br><span class="line">                 players=[Agent(Race.terran), Bot(Race.terran, Difficulty.very_easy)],</span><br><span class="line">                 agent_interface_format=AgentInterfaceFormat(feature_dimensions=Dimensions(screen=<span class="number">84</span>, minimap=<span class="number">64</span>)),</span><br><span class="line">                 step_mul=<span class="number">16</span>, visualize=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        loop(agent, env)</span><br><span class="line">    <span class="keyword">except</span> KeyboardInterrupt:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Finished!&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    app.run(main)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Tutorial</category>
      </categories>
      <tags>
        <tag>Reinforcement Learning</tag>
        <tag>PySC2</tag>
        <tag>Tools</tag>
      </tags>
  </entry>
  <entry>
    <title>Use PySC2 Learning Environment - Define Your Own Agent</title>
    <url>/2022/2-tutorial-pysc2-2/</url>
    <content><![CDATA[<p>This is a brief introduction to an easy approach to use the
<code>PySC2</code> by defining your own agent. A basic template for a
self-defined agent can be found <a
href="https://github.com/mhz2180572509/HowToUsePySC2/blob/main/Approach_1.py">here</a>.
(The codes are also attached at the end).</p>
<ul>
<li>For an overview of <code>PySC2</code>, you can proceed to
<a href="/2022/1-tutorial-pysc2-1/" title="A Brief Tutorial to Use PySC2 Learning Environment (Overview)">A Brief Tutorial to Use PySC2 Learning Environment (Overview)</a>.</li>
<li>For an more comprehensive approach to define your own environment
and agent, and also control the interaction between them, you can
proceed to <a href="/2022/3-tutorial-pysc2-3/" title="Use PySC2 Learning Environment - Control Your Own Environment and Agent">Use PySC2 Learning Environment - Control Your Own Environment and Agent</a></li>
</ul>
<span id="more"></span>
<h1 id="how-to-use-custom-defined-agents">How to Use Custom-Defined
Agents?</h1>
<p>Run the command:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python -m pysc2.bin.agent --map &lt;Map&gt; --agent &lt;Agent&gt;</span><br></pre></td></tr></table></figure>
<p>Assuming that your own agent class named
<code>MyAgentClassName</code> is defined in <code>MyAgentFile.py</code>
in a directory <code>[PATH]</code>, then when you run command in the
<code>[PATH]</code> directory, you can identify the agent by:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python -m pysc2.bin.agent --map &lt;Map&gt; --agent MyAgentFile.MyAgentClassName</span><br></pre></td></tr></table></figure>
<h1 id="how-to-design-my-own-agent-and-make-it-interact-with-pysc2">How
to Design My Own Agent and Make It Interact with PySC2?</h1>
<p>Any custom designed agent should derive from the
<code>BaseAgent</code> class (in <code>pysc2.agents.base_agent</code>)
and override the <code>step(self, obs)</code> function, where the
argument <code>obs</code> is the observations.</p>
<h1 id="how-to-get-observations-and-rewards-from-the-environment">How to
Get Observations and Rewards from The Environment?</h1>
<p>The observations (as well as the rewards) taken from environment are
all included in the parameter <code>obs</code> of the <code>step</code>
function, such as the feature maps, valid actions, rewards and so
on.</p>
<p>for example: * state, viz. different types of feature maps:
<code>obs.observation["screen"][feature_map_name]</code> * valid
actions: <code>obs.observation["available_actions"]</code> or
<code>obs.observation.available_actions</code> * rewards:
<code>obs.reward</code></p>
<h1 id="how-to-send-actions-to-interact-with-the-environment">How to
Send Actions to Interact with The Environment?</h1>
<p>In the <code>step</code> function, return the action (packed up as a
<code>FunctionCall</code> instance).</p>
<h1 id="more-reference">More Reference</h1>
<ul>
<li>A random agent: <a
href="https://github.com/deepmind/pysc2/blob/master/pysc2/agents/random_agent.py"
class="uri">https://github.com/deepmind/pysc2/blob/master/pysc2/agents/random_agent.py</a></li>
<li>A scripted agent: <a
href="https://github.com/deepmind/pysc2/blob/master/pysc2/agents/scripted_agent.py"
class="uri">https://github.com/deepmind/pysc2/blob/master/pysc2/agents/scripted_agent.py</a></li>
</ul>
<h1 id="template-codes">Template Codes</h1>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">A template for approach 1.</span></span><br><span class="line"><span class="string">The agent randomly selects actions.</span></span><br><span class="line"><span class="string">Use the `pysc2.bin.agent` module to run `MyAgent` when your commands are in the current path:</span></span><br><span class="line"><span class="string">    python -m pysc2.bin.agent --map &lt;MAP_NAME&gt; --agent pysc2EnvTemplate.MyAgent</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># to be compatible with python 2.x</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> absolute_import</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> division</span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># import the BaseAgent class which we should derive from</span></span><br><span class="line"><span class="keyword">from</span> pysc2.agents <span class="keyword">import</span> base_agent</span><br><span class="line"><span class="comment"># import actions</span></span><br><span class="line"><span class="keyword">from</span> pysc2.lib <span class="keyword">import</span> actions</span><br><span class="line"><span class="comment"># import features</span></span><br><span class="line"><span class="keyword">from</span> pysc2.lib <span class="keyword">import</span> features</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># define our own agent</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyAgent</span>(<span class="params">base_agent.BaseAgent</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">step</span>(<span class="params">self, obs</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MyAgent, self).step(obs)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># -------------------#</span></span><br><span class="line">        <span class="comment"># RL algorithm here~ #</span></span><br><span class="line">        <span class="comment"># -------------------#</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># get available actions</span></span><br><span class="line">        function_id = np.random.choice(obs.observation.available_actions)</span><br><span class="line">        <span class="comment"># randomly select one action and its argument</span></span><br><span class="line">        args = [[np.random.randint(<span class="number">0</span>, size) <span class="keyword">for</span> size <span class="keyword">in</span> arg.sizes]</span><br><span class="line">                <span class="keyword">for</span> arg <span class="keyword">in</span> self.action_spec.functions[function_id].args]</span><br><span class="line">        <span class="comment"># pack up the actions as a `FunctionCall`</span></span><br><span class="line">        function_call = actions.FunctionCall(function_id, args)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># return the actions a.k.a. the function_call</span></span><br><span class="line">        <span class="keyword">return</span> function_call</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Tutorial</category>
      </categories>
      <tags>
        <tag>Reinforcement Learning</tag>
        <tag>PySC2</tag>
        <tag>Tools</tag>
      </tags>
  </entry>
</search>
