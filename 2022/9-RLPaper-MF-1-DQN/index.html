<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.9.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>
<meta name="description" content="[1] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller. 2013. Playing Atari with Deep Reinforcement Learning. DOI:https:&#x2F;&#x2F;doi.or">
<meta property="og:type" content="article">
<meta property="og:title" content="[DQN] Deep Q-Learning Networks">
<meta property="og:url" content="http://example.com/2022/9-RLPaper-MF-1-DQN/">
<meta property="og:site_name" content="Life like Wine">
<meta property="og:description" content="[1] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves, Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller. 2013. Playing Atari with Deep Reinforcement Learning. DOI:https:&#x2F;&#x2F;doi.or">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/images/RLPapers/Model-Free/DeepQLearning/1-1.png">
<meta property="og:image" content="http://example.com/images/RLPapers/Model-Free/DeepQLearning/1-2.png">
<meta property="og:image" content="http://example.com/images/RLPapers/Model-Free/DeepQLearning/1-3.png">
<meta property="article:published_time" content="2022-08-09T12:32:21.261Z">
<meta property="article:modified_time" content="2022-08-09T12:32:54.037Z">
<meta property="article:author" content="Ma Haozhe">
<meta property="article:tag" content="Reinforcement Learning">
<meta property="article:tag" content="Paper Notes">
<meta property="article:tag" content="Model-Free RL">
<meta property="article:tag" content="Deep Q-Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/RLPapers/Model-Free/DeepQLearning/1-1.png">


<link rel="canonical" href="http://example.com/2022/9-RLPaper-MF-1-DQN/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2022/9-RLPaper-MF-1-DQN/","path":"2022/9-RLPaper-MF-1-DQN/","title":"[DQN] Deep Q-Learning Networks"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>[DQN] Deep Q-Learning Networks | Life like Wine</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Life like Wine</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#overview"><span class="nav-number">1.</span> <span class="nav-text">Overview</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#main-problems-to-solve"><span class="nav-number">2.</span> <span class="nav-text">Main Problems to Solve</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#main-innovations"><span class="nav-number">3.</span> <span class="nav-text">Main Innovations</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#implementation-details"><span class="nav-number">4.</span> <span class="nav-text">Implementation Details</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Ma Haozhe"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Ma Haozhe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">9</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/mhz2180572509" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;mhz2180572509" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:haozhe.ma@u.nus.edu" title="E-Mail → mailto:haozhe.ma@u.nus.edu" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/9-RLPaper-MF-1-DQN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Ma Haozhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Life like Wine">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          [DQN] Deep Q-Learning Networks
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-08-09 20:32:21 / Modified: 20:32:54" itemprop="dateCreated datePublished" datetime="2022-08-09T20:32:21+08:00">2022-08-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/RL-Paper-Notes/" itemprop="url" rel="index"><span itemprop="name">RL Paper Notes</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <blockquote>
<p>[1] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves,
Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller. 2013. Playing
Atari with Deep Reinforcement Learning. DOI:<a
target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.1312.5602"
class="uri">https://doi.org/10.48550/arXiv.1312.5602</a></p>
</blockquote>
<blockquote>
<p>[2] Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Andrei A. Rusu,
Joel Veness, Marc G. Bellemare, Alex Graves, Martin Riedmiller, Andreas
K. Fidjeland, Georg Ostrovski, Stig Petersen, Charles Beattie, Amir
Sadik, Ioannis Antonoglou, Helen King, Dharshan Kumaran, Daan Wierstra,
Shane Legg, and Demis Hassabis. 2015. Human-level control through deep
reinforcement learning. Nature 518, 7540 (February 2015), 529–533.
DOI:<a target="_blank" rel="noopener" href="https://doi.org/10.1038/nature14236"
class="uri">https://doi.org/10.1038/nature14236</a></p>
</blockquote>
<span id="more"></span>
<figure>
<img src="/images/RLPapers/Model-Free/DeepQLearning/1-1.png"
alt="Playing Atari with Deep Reinforcement Learning." />
<figcaption aria-hidden="true">Playing Atari with Deep Reinforcement
Learning.</figcaption>
</figure>
<figure>
<img src="/images/RLPapers/Model-Free/DeepQLearning/1-2.png"
alt="Human-level control through deep reinforcement learning." />
<figcaption aria-hidden="true">Human-level control through deep
reinforcement learning.</figcaption>
</figure>
<h1 id="overview">Overview</h1>
<p>The proposed <strong><em>Deep Q-Learning Network</em></strong>
(<strong><em>DQN</em></strong>) is the first algorithm to introduce
(deep) neural networks as function approximators (in other words,
non-linear function approximators) into reinforcement learning. DQN is a
<strong>model-free</strong>, <strong>off-policy</strong>,
<strong>(Q-)value based</strong> algorithm, which can be implemented
onto environments with continuous state space but only with discrete
action space. DQN can be trained <strong>end-to-end</strong>, which
means it could receive high-dimensional state's representations as
input. The paper evaluated the DQN on 7 Atari games and 49 Atari games
with the same hyper-parameters which shows the great generalization
ability of DQN.</p>
<h1 id="main-problems-to-solve">Main Problems to Solve</h1>
<p>To introduce deep neural networks (non-linear functions) as
approximators in reinforcement learning has to overcome some
problems:</p>
<ol type="1">
<li>Most deep learning algorithms (like classifications, regressions)
assume that the data samples are independent, however, in RL
environments, the samples in a sequence are <strong>highly
correlated</strong>.</li>
<li>Most deep learning algorithms require large amounts of hand-labelled
training data, however, RL algorithms need to learn from observations
and information directly from environment, e.g., the scalar reward
signals, which is frequently sparse, noisy and delayed.</li>
<li>Most deep learning methods assume they are learnt in a fixed
underlaying distribution, however, in RL, the <strong>data distribution
changes</strong> as the agents updates their behaviors during the
learning process.</li>
</ol>
<h1 id="main-innovations">Main Innovations</h1>
<p>The paper mainly proposed two techniques to overcome the problems:
(a) <strong>experience replay</strong> and (b) <strong>target network
with periodically update</strong>:</p>
<ol type="1">
<li>Experience replay: initialize a replay buffer and store the
transitions <span class="math inline">\(\{s_t,a_t,r_t,s_{t+1}\}\)</span>
in it, for each iteration, randomly draw samples from the replay buffer
and train the network using stochastic gradient descent (SGD).
<ul>
<li>Can break the correlations among samples so as to reduce the
variance</li>
<li>Each sample can be drawn in many rounds of updates, which allows for
greater data efficiency.</li>
</ul></li>
<li>Target network with periodically update: the algorithm initializes
two networks with the same hyper-parameters and architecture, for each
iteration, update the policy network with SGD, for each <span
class="math inline">\(K\)</span> (a hyper-parameter) iterations,
directly copy the parameters in policy network to target network. In the
training, the action is selected by target network.
<ul>
<li>The distribution of the behavior to select the action can be
smooth.</li>
</ul></li>
</ol>
<p>The algorithm:</p>
<figure>
<img src="/images/RLPapers/Model-Free/DeepQLearning/1-3.png"
alt="DQN algorithm." />
<figcaption aria-hidden="true">DQN algorithm.</figcaption>
</figure>
<h1 id="implementation-details">Implementation Details</h1>
<ul>
<li>Using an adaptive learning rate method such as RMSProp or ADADELTA
that maintains a per-parameter learning rate α, and adjusts α according
to the history of gradient updates to that parameter.</li>
<li>Using the <strong>last 4 frames</strong> of a history and stacks
them as the input to the Q-network, which can capture the information
about objects' speed and acceleration.</li>
<li>Pre-processing to change the RGB screens to gray-scale images and
crop the central part.</li>
<li>During the training, the agent observes the environment and selects
an action for each <span class="math inline">\(k\)</span> frames of the
video game.</li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Reinforcement-Learning/" rel="tag"># Reinforcement Learning</a>
              <a href="/tags/Paper-Notes/" rel="tag"># Paper Notes</a>
              <a href="/tags/Model-Free-RL/" rel="tag"># Model-Free RL</a>
              <a href="/tags/Deep-Q-Learning/" rel="tag"># Deep Q-Learning</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/8-ProbabilisticML-5-MCMCHMM/" rel="prev" title="Markov Chain Monte Carlo (MCMC) Estimation of Hidden Markov Model (HMM)">
                  <i class="fa fa-chevron-left"></i> Markov Chain Monte Carlo (MCMC) Estimation of Hidden Markov Model (HMM)
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ma Haozhe</span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
