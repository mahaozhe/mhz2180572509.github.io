<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.9.0","exturl":false,"sidebar":{"position":"left","display":"always","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>
<meta name="description" content="Ziyu Wang, Tom Schaul, Matteo Hessel, Hado Hasselt, Marc Lanctot, and Nando Freitas. 2016. Dueling Network Architectures for Deep Reinforcement Learning. In Proceedings of The 33rd International">
<meta property="og:type" content="article">
<meta property="og:title" content="[Dueling DQN] Dueling Network Architectures for Deep Reinforcement Learning">
<meta property="og:url" content="http://example.com/2022/12-RLPaper-MF-4-DuelingDQN/">
<meta property="og:site_name" content="Life like Wine">
<meta property="og:description" content="Ziyu Wang, Tom Schaul, Matteo Hessel, Hado Hasselt, Marc Lanctot, and Nando Freitas. 2016. Dueling Network Architectures for Deep Reinforcement Learning. In Proceedings of The 33rd International">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/images/RLPapers/Model-Free/DeepQLearning/4-1.png">
<meta property="og:image" content="http://example.com/images/RLPapers/Model-Free/DeepQLearning/4-2.png">
<meta property="article:published_time" content="2022-08-09T12:53:14.297Z">
<meta property="article:modified_time" content="2022-08-09T12:56:11.043Z">
<meta property="article:author" content="Ma Haozhe">
<meta property="article:tag" content="Reinforcement Learning">
<meta property="article:tag" content="Paper Notes">
<meta property="article:tag" content="Model-Free RL">
<meta property="article:tag" content="Deep Q-Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/RLPapers/Model-Free/DeepQLearning/4-1.png">


<link rel="canonical" href="http://example.com/2022/12-RLPaper-MF-4-DuelingDQN/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2022/12-RLPaper-MF-4-DuelingDQN/","path":"2022/12-RLPaper-MF-4-DuelingDQN/","title":"[Dueling DQN] Dueling Network Architectures for Deep Reinforcement Learning"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>[Dueling DQN] Dueling Network Architectures for Deep Reinforcement Learning | Life like Wine</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Life like Wine</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#overview"><span class="nav-number">1.</span> <span class="nav-text">Overview</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#main-problems-to-solve"><span class="nav-number">2.</span> <span class="nav-text">Main Problems to Solve</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#main-innovations"><span class="nav-number">3.</span> <span class="nav-text">Main Innovations</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Ma Haozhe"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Ma Haozhe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">18</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">3</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/mhz2180572509" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;mhz2180572509" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i></a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:haozhe.ma@u.nus.edu" title="E-Mail → mailto:haozhe.ma@u.nus.edu" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i></a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/12-RLPaper-MF-4-DuelingDQN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Ma Haozhe">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Life like Wine">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          [Dueling DQN] Dueling Network Architectures for Deep Reinforcement Learning
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-08-09 20:53:14 / Modified: 20:56:11" itemprop="dateCreated datePublished" datetime="2022-08-09T20:53:14+08:00">2022-08-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/RL-Paper-Notes/" itemprop="url" rel="index"><span itemprop="name">RL Paper Notes</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <blockquote>
<p>Ziyu Wang, Tom Schaul, Matteo Hessel, Hado Hasselt, Marc Lanctot, and
Nando Freitas. 2016. Dueling Network Architectures for Deep
Reinforcement Learning. In Proceedings of The 33rd International
Conference on Machine Learning, PMLR, 1995–2003. Retrieved August 8,
2022 from https://proceedings.mlr.press/v48/wangf16.html</p>
</blockquote>
<span id="more"></span>
<figure>
<img src="/images/RLPapers/Model-Free/DeepQLearning/4-1.png"
alt="Dueling Network Architectures for Deep Reinforcement Learning" />
<figcaption aria-hidden="true">Dueling Network Architectures for Deep
Reinforcement Learning</figcaption>
</figure>
<h1 id="overview">Overview</h1>
<p>The paper proposed a creative network <strong>architecture</strong>
called <strong><em>dueling network</em></strong> to <strong>decouple the
value and advantage</strong> in deep Q-networks algorithm. The
architecture can be used to replace the original network in any
applicable deep RL algorithm without imposing any change to the
underlying algorithm. The authors conducted experiments to show better
performances that outperform the state-of-the-art algorithms (2016-6) on
Atari games domain.</p>
<h1 id="main-problems-to-solve">Main Problems to Solve</h1>
<p>The new architecture main solves the following problems:</p>
<ul>
<li>In most environments, for many states, the selection of actions is
almost irrelevant, which means, for these states, selecting any action
by the agent does not affect the environment any more.</li>
<li>In most popular deep RL algorithms, like DQN, DDQN, the difference
of the Q-values among different actions are usually very small, which is
easy to be influenced by any noise or oscillation.</li>
</ul>
<h1 id="main-innovations">Main Innovations</h1>
<p>The proposed architecture is shown in the following figure:</p>
<figure>
<img src="/images/RLPapers/Model-Free/DeepQLearning/4-2.png"
alt="Dueling network architecture" />
<figcaption aria-hidden="true">Dueling network architecture</figcaption>
</figure>
<p>At the end of the convolutional layers, the dueling network separate
the output to two streams, one to estimate the state value <span
class="math inline">\(V(s)\)</span> (a scaler) and one to estimate the
<strong><em>advantage function</em></strong> of each action for the
current state <span class="math inline">\(A(s,a)\)</span> (a vector with
length of <span class="math inline">\(|A|\)</span>). Then the network
use a sepcial <strong>aggregating layer</strong> to combine the value
and the advantage together to output the Q-value <span
class="math inline">\(Q(s,a)\)</span>.</p>
<p>The relationship among these qualities under a specific policy <span
class="math inline">\(\pi\)</span> is:</p>
<p><span class="math display">\[\begin{equation}
A^{\pi}(s,a)=Q^{\pi}(s,a)−V^{\pi}(s)
\end{equation}\]</span></p>
<p>which indicates that the advantage is the Q-value but measured by the
value of that state, in this case, we actually have: <span
class="math inline">\(\mathbb{E}_{a \backsim
\pi(s)}[A^{\pi}(s,a)]=0\)</span>. The advantage is a <strong>relative
measure</strong> of the importance of each action.</p>
<p>One important problem is that: actually, in deep Q-networks based
algorithms, we only estimate the final output Q-values in the algorithm,
but not explicitly estimate or give out the state values and action
advantages, and we cannot <strong>recover</strong> these two values only
based on the given Q-value. So, to address this issue of identifiability
problem, the paper <strong>forced the advantage function estimator to
offset by the maximal of all advantages or the average of all
advantages</strong>:</p>
<ul>
<li><span
class="math inline">\(Q(s,a)=V(s)+(A(s,a)−\max_{a&#39;}⁡{A(s,a&#39;)})\)</span></li>
<li><span
class="math inline">\(Q(s,a)=V(s)+(A(s,a)−\frac{1}{|A|}\sum_{a&#39;}{A(s,a&#39;)})\)</span></li>
</ul>
<p>This trick, on the one hand, loses the original semantics of V and A
because they are now off-target by a constant, but on the other hand, it
increases the stability of the optimization. What's more, this doesn't
change the relative rank of the A (and hence Q) values and the values
can be computed <strong>automatically</strong>.</p>
<p>The paper evaluated the performance of the above two methods, and
show the results based on the second equation.</p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Reinforcement-Learning/" rel="tag"># Reinforcement Learning</a>
              <a href="/tags/Paper-Notes/" rel="tag"># Paper Notes</a>
              <a href="/tags/Model-Free-RL/" rel="tag"># Model-Free RL</a>
              <a href="/tags/Deep-Q-Learning/" rel="tag"># Deep Q-Learning</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/11-RLPaper-MF-3-DDQN/" rel="prev" title="[DDQN] Deep Reinforcement Learning with Double Q-Learning">
                  <i class="fa fa-chevron-left"></i> [DDQN] Deep Reinforcement Learning with Double Q-Learning
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/13-RLPaper-Te-ER-1-PER/" rel="next" title="[PER] Prioritized Experience Replay">
                  [PER] Prioritized Experience Replay <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ma Haozhe</span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
